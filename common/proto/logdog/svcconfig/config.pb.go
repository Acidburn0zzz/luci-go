// Code generated by protoc-gen-go.
// source: config.proto
// DO NOT EDIT!

/*
Package svcconfig is a generated protocol buffer package.

It is generated from these files:
	config.proto
	storage.proto
	transport.proto

It has these top-level messages:
	Config
	Coordinator
	Collector
	Archivist
	Storage
	Transport
*/
package svcconfig

import proto "github.com/golang/protobuf/proto"
import fmt "fmt"
import math "math"
import google_protobuf "github.com/luci/luci-go/common/proto/google"

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// Config is the overall instance configuration.
type Config struct {
	// Configuration for the Pub/Sub instances.
	Transport *Transport `protobuf:"bytes,10,opt,name=transport" json:"transport,omitempty"`
	// Configuration for Storage.
	Storage *Storage `protobuf:"bytes,11,opt,name=storage" json:"storage,omitempty"`
	// Coordinator is the coordinator service configuration.
	Coordinator *Coordinator `protobuf:"bytes,20,opt,name=coordinator" json:"coordinator,omitempty"`
	// Collector is the collector fleet configuration.
	Collector *Collector `protobuf:"bytes,21,opt,name=collector" json:"collector,omitempty"`
	// Archivist microservice configuration.
	Archivist *Archivist `protobuf:"bytes,22,opt,name=archivist" json:"archivist,omitempty"`
}

func (m *Config) Reset()                    { *m = Config{} }
func (m *Config) String() string            { return proto.CompactTextString(m) }
func (*Config) ProtoMessage()               {}
func (*Config) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{0} }

func (m *Config) GetTransport() *Transport {
	if m != nil {
		return m.Transport
	}
	return nil
}

func (m *Config) GetStorage() *Storage {
	if m != nil {
		return m.Storage
	}
	return nil
}

func (m *Config) GetCoordinator() *Coordinator {
	if m != nil {
		return m.Coordinator
	}
	return nil
}

func (m *Config) GetCollector() *Collector {
	if m != nil {
		return m.Collector
	}
	return nil
}

func (m *Config) GetArchivist() *Archivist {
	if m != nil {
		return m.Archivist
	}
	return nil
}

// Coordinator is the Coordinator service configuration.
type Coordinator struct {
	// Project is the name of the AppEngine Project that the Coordinator belongs
	// to.
	Project string `protobuf:"bytes,1,opt,name=project" json:"project,omitempty"`
	// The name of the authentication group for administrators.
	AdminAuthGroup string `protobuf:"bytes,10,opt,name=admin_auth_group" json:"admin_auth_group,omitempty"`
	// The name of the authentication group for backend services.
	ServiceAuthGroup string `protobuf:"bytes,11,opt,name=service_auth_group" json:"service_auth_group,omitempty"`
	// A list of origin URLs that are allowed to perform CORS RPC calls.
	RpcAllowOrigins []string `protobuf:"bytes,20,rep,name=rpc_allow_origins" json:"rpc_allow_origins,omitempty"`
	// The name of the archive task queue.
	ArchiveTaskQueue string `protobuf:"bytes,30,opt,name=archive_task_queue" json:"archive_task_queue,omitempty"`
	// The amount of time after a log has been terminated before it is candidate
	// for archival.
	//
	// Archival triggered by this delay will NOT succeed if any log entries are
	// missing from intermediate storage.
	//
	// This should be based on a period of time where it's reasonable to expect
	// that all log messages in the transport have arrived for a given log stream.
	// Since the transport doesn't have to guarantee in-order delivery, this
	// should allow for the case where the terminal log entry arrives before some
	// of the intermediate log entries. This will help avoid triggering
	// archive attempts that are doomed to fail because of standard transport lag.
	ArchiveDelay *google_protobuf.Duration `protobuf:"bytes,31,opt,name=archive_delay" json:"archive_delay,omitempty"`
	// The amount of time before a log stream is candidate for archival regardless
	// of whether or not it's been terminated or complete.
	//
	// This endpoint is a failsafe designed to ensure that log streams with
	// missing records or no terminal record (e.g., Butler crashed) are eventually
	// moved out of intermediate storage.
	//
	// This must be >= `archive_delay`, and should be fairly large (days) to allow
	// for the log stream to complete and for all available log entries to be
	// added to intermediate storage.
	ArchiveDelayMax *google_protobuf.Duration `protobuf:"bytes,32,opt,name=archive_delay_max" json:"archive_delay_max,omitempty"`
	// The name of the storage cleanup task queue.
	StorageCleanupTaskQueue string `protobuf:"bytes,40,opt,name=storage_cleanup_task_queue" json:"storage_cleanup_task_queue,omitempty"`
	// The amount of time to wait before initiating a storage cleanup task.
	StorageCleanupDelay *google_protobuf.Duration `protobuf:"bytes,41,opt,name=storage_cleanup_delay" json:"storage_cleanup_delay,omitempty"`
}

func (m *Coordinator) Reset()                    { *m = Coordinator{} }
func (m *Coordinator) String() string            { return proto.CompactTextString(m) }
func (*Coordinator) ProtoMessage()               {}
func (*Coordinator) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{1} }

func (m *Coordinator) GetArchiveDelay() *google_protobuf.Duration {
	if m != nil {
		return m.ArchiveDelay
	}
	return nil
}

func (m *Coordinator) GetArchiveDelayMax() *google_protobuf.Duration {
	if m != nil {
		return m.ArchiveDelayMax
	}
	return nil
}

func (m *Coordinator) GetStorageCleanupDelay() *google_protobuf.Duration {
	if m != nil {
		return m.StorageCleanupDelay
	}
	return nil
}

// Collector is the set of configuration parameters for Collector instances.
type Collector struct {
	// Workers is the number of ingest workers to run.
	Workers int32 `protobuf:"varint,1,opt,name=workers" json:"workers,omitempty"`
	// The number of transport worker goroutines to run.
	TransportWorkers int32 `protobuf:"varint,2,opt,name=transport_workers" json:"transport_workers,omitempty"`
	// The maximum number of log stream states to cache locally. If <= 0, a
	// default will be used.
	StateCacheSize int32 `protobuf:"varint,3,opt,name=state_cache_size" json:"state_cache_size,omitempty"`
	// The maximum amount of time that cached stream state is valid. If <= 0, a
	// default will be used.
	StateCacheExpiration *google_protobuf.Duration `protobuf:"bytes,4,opt,name=state_cache_expiration" json:"state_cache_expiration,omitempty"`
}

func (m *Collector) Reset()                    { *m = Collector{} }
func (m *Collector) String() string            { return proto.CompactTextString(m) }
func (*Collector) ProtoMessage()               {}
func (*Collector) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{2} }

func (m *Collector) GetStateCacheExpiration() *google_protobuf.Duration {
	if m != nil {
		return m.StateCacheExpiration
	}
	return nil
}

// Configuration for the Archivist microservice.
type Archivist struct {
	// The number of tasks to run at a time. If blank, the archivist will choose a
	// default value.
	Tasks int32 `protobuf:"varint,1,opt,name=tasks" json:"tasks,omitempty"`
	// The name of the Google Storage bucket and optional base path to archive
	// into. For example: gs://foo/bar
	//
	// The bucket name must be included (e.g., "gs://foo"). The remainder of the
	// base path is optional based on desired archive location.
	GsBase string `protobuf:"bytes,10,opt,name=gs_base" json:"gs_base,omitempty"`
	// If not zero, the maximum number of stream indices between index entries.
	StreamIndexRange int32 `protobuf:"varint,11,opt,name=stream_index_range" json:"stream_index_range,omitempty"`
	// If not zero, the maximum number of prefix indices between index entries.
	PrefixIndexRange int32 `protobuf:"varint,12,opt,name=prefix_index_range" json:"prefix_index_range,omitempty"`
	// If not zero, the maximum number of log data bytes between index entries.
	ByteRange int32 `protobuf:"varint,13,opt,name=byte_range" json:"byte_range,omitempty"`
}

func (m *Archivist) Reset()                    { *m = Archivist{} }
func (m *Archivist) String() string            { return proto.CompactTextString(m) }
func (*Archivist) ProtoMessage()               {}
func (*Archivist) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{3} }

func init() {
	proto.RegisterType((*Config)(nil), "svcconfig.Config")
	proto.RegisterType((*Coordinator)(nil), "svcconfig.Coordinator")
	proto.RegisterType((*Collector)(nil), "svcconfig.Collector")
	proto.RegisterType((*Archivist)(nil), "svcconfig.Archivist")
}

var fileDescriptor0 = []byte{
	// 462 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x09, 0x6e, 0x88, 0x02, 0xff, 0x84, 0x92, 0xc1, 0x72, 0xd3, 0x30,
	0x10, 0x86, 0x27, 0x2d, 0x69, 0xc7, 0xeb, 0x66, 0x4a, 0x35, 0x6d, 0x46, 0xcd, 0xa1, 0x74, 0xc2,
	0x81, 0x32, 0xcc, 0xb8, 0x0c, 0x70, 0x80, 0x23, 0x13, 0xde, 0x00, 0xee, 0x1a, 0x45, 0xde, 0x38,
	0xa2, 0x8e, 0x64, 0x24, 0x39, 0x49, 0x79, 0x06, 0x5e, 0x8e, 0x03, 0xef, 0x83, 0x2c, 0xd9, 0xa9,
	0xdb, 0x1e, 0x72, 0xd4, 0x7e, 0xff, 0xee, 0xfe, 0xbb, 0x2b, 0x38, 0x11, 0x5a, 0x2d, 0x64, 0x91,
	0x55, 0x46, 0x3b, 0x4d, 0x12, 0xbb, 0x16, 0x31, 0x30, 0x39, 0x75, 0x86, 0x2b, 0x5b, 0x69, 0xe3,
	0x22, 0x9b, 0x8c, 0xac, 0xd3, 0x86, 0x17, 0xd8, 0x3e, 0xaf, 0x0a, 0xad, 0x8b, 0x12, 0x6f, 0xc3,
	0x6b, 0x5e, 0x2f, 0x6e, 0xf3, 0xda, 0x70, 0x27, 0xb5, 0x8a, 0x7c, 0xfa, 0x6f, 0x00, 0x47, 0xb3,
	0x50, 0x8a, 0xbc, 0x81, 0x64, 0x57, 0x8c, 0xc2, 0xf5, 0xe0, 0x26, 0xfd, 0x70, 0x9e, 0xed, 0x3a,
	0x65, 0x3f, 0x3a, 0x46, 0x5e, 0xc3, 0x71, 0xdb, 0x84, 0xa6, 0x41, 0x46, 0x7a, 0xb2, 0xef, 0x91,
	0x90, 0x77, 0x90, 0x0a, 0xad, 0x4d, 0x2e, 0x15, 0xf7, 0x11, 0x7a, 0x1e, 0x84, 0xe3, 0x9e, 0x70,
	0xf6, 0x40, 0x9b, 0xd6, 0x42, 0x97, 0x25, 0x8a, 0x46, 0x7a, 0xf1, 0xac, 0xf5, 0xac, 0x63, 0x8d,
	0x90, 0x1b, 0xb1, 0x94, 0x6b, 0x69, 0x1d, 0x1d, 0x3f, 0x13, 0x7e, 0xed, 0xd8, 0xf4, 0xef, 0x01,
	0xa4, 0xfd, 0x0e, 0xa7, 0x70, 0xec, 0x07, 0xfe, 0xe9, 0xab, 0xd0, 0x81, 0x4f, 0x4b, 0x08, 0x85,
	0x97, 0x3c, 0x5f, 0x49, 0xc5, 0x78, 0xed, 0x96, 0xac, 0x30, 0xba, 0xae, 0xc2, 0xd0, 0x09, 0x99,
	0x00, 0xb1, 0x68, 0xd6, 0x52, 0x60, 0x9f, 0xa5, 0x81, 0x5d, 0xc2, 0x99, 0xa9, 0x04, 0xe3, 0x65,
	0xa9, 0x37, 0x4c, 0x1b, 0x59, 0x48, 0x65, 0xfd, 0x6c, 0x87, 0x31, 0x2d, 0x5a, 0x43, 0xe6, 0xb8,
	0xbd, 0x63, 0xbf, 0x6a, 0xac, 0x91, 0x5e, 0x85, 0xb4, 0xf7, 0x30, 0xea, 0x58, 0x8e, 0x25, 0xbf,
	0xa7, 0xaf, 0x82, 0xf5, 0xcb, 0x2c, 0x5e, 0x27, 0xeb, 0xae, 0x93, 0x7d, 0x6b, 0xaf, 0x43, 0x3e,
	0xc1, 0xd9, 0xa3, 0x0c, 0xb6, 0xe2, 0x5b, 0x7a, 0xbd, 0x2f, 0x6b, 0x0a, 0x93, 0xf6, 0x32, 0x4c,
	0x94, 0xc8, 0x55, 0x5d, 0xf5, 0xbd, 0xdc, 0x04, 0x2f, 0x9f, 0xe1, 0xe2, 0xa9, 0x26, 0x7a, 0x7a,
	0xbb, 0xa7, 0xfa, 0xf4, 0xcf, 0x00, 0x92, 0x87, 0x53, 0xf8, 0x8d, 0x6e, 0xb4, 0xb9, 0x43, 0x63,
	0xc3, 0x46, 0x87, 0xcd, 0x6e, 0x76, 0xff, 0x87, 0x75, 0xe8, 0x20, 0x20, 0xbf, 0x6c, 0xeb, 0xb8,
	0xf3, 0x1d, 0xb9, 0x58, 0x22, 0xb3, 0xf2, 0x37, 0xd2, 0xc3, 0x40, 0xbe, 0xc0, 0xb8, 0x4f, 0x70,
	0x5b, 0xc9, 0xd8, 0x8d, 0xbe, 0xd8, 0x67, 0x67, 0x03, 0xc9, 0xee, 0xde, 0x64, 0x04, 0xc3, 0x66,
	0xd2, 0xce, 0x8b, 0x37, 0x57, 0x58, 0x36, 0xe7, 0x16, 0x7b, 0x47, 0x75, 0x06, 0xf9, 0x8a, 0x49,
	0x95, 0xe3, 0x96, 0x79, 0xa3, 0xed, 0xf7, 0x1d, 0x36, 0xac, 0x32, 0xb8, 0x90, 0xdb, 0x47, 0xec,
	0x24, 0x30, 0x02, 0x30, 0xbf, 0xf7, 0xf6, 0x62, 0x6c, 0xd4, 0xc4, 0xe6, 0x47, 0xc1, 0xcb, 0xc7,
	0xff, 0x01, 0x00, 0x00, 0xff, 0xff, 0x60, 0xa0, 0xfa, 0x1c, 0x95, 0x03, 0x00, 0x00,
}
